#!/usr/bin/env python

# Copyright 2016 The Jackson Laboratory
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


#   report on the status of a pipeline.  The pipeline is specified by providing
#   the path to its log directory, which is unique for each pipeline


from __future__ import print_function

import argparse
import sys
import os
import inspect
import json
import shutil

cmd_folder = os.path.realpath(os.path.abspath(os.path.split(inspect.getfile(inspect.currentframe()))[0]))
lib_folder = os.path.join(cmd_folder, '../lib')
if lib_folder not in sys.path:
    sys.path.insert(0, lib_folder)

import job_runner.common
import version
import status
from exec_modes import ToolExecModes

FAILURE_STATUSES = [
    'CANCELED',
    'FAILED',
    'TERMINATED',
]


def recursive_remove(analysis_directory):
    """
    Recursively remove a directory specified by path, and all of the
    contained files.
    :param analysis_directory: The path to a directory to be removed.
    :return: None
    """
    # I think this is important enough to put it out even if not in
    # verbose mode...
    print("Deleting failed analysis directory {}".format(
        analysis_directory
    ))
    try:
        shutil.rmtree(analysis_directory)
    except Exception as e:
        print('Failure removing analysis directory {}:\n    {}'.format(
            analysis_directory, e), file=sys.stderr)


def check_remove_run(dir_status, remove_statuses):
    """
    Check whether the user asked for analysis runs with this type of failure
    should be removed (deleted from the disk).  This routine isn't called
    at all if the user didn't request some form of failure to be removed.
    :param dir_status: The dir_status object for this log directory.
    :param remove_statuses: The list of failure types to be removed.
    :return: None
    """
    # Check whether this is a failed job:
    if dir_status.status in FAILURE_STATUSES:
        # Now, check whether the user asked for failures of this type to be
        # deleted
        if 'ALL' in remove_statuses or dir_status.status in remove_statuses:
            analysis_directory = os.path.dirname(
                os.path.dirname(dir_status.log_dir))
            recursive_remove(analysis_directory)


def main():

    parser = argparse.ArgumentParser(prog=os.path.basename(sys.argv[0]))
    parser.add_argument('-r', '--recursive',
                        action='store_true', help="Run in recursive mode")
    parser.add_argument('--verbose', action='store_true',
                        help="More verbose output")
    parser.add_argument('--json', action='store_true',
                        help="Output status in JSON format. "
                             "Overrides --verbose and --quiet options.")
    parser.add_argument('-q', '--quiet', action='store_true',
                        help="Only produce output for failed runs")
    parser.add_argument('-f', '--fast', action='store_true',
                        help="Use 'fast' recursive mode (when recursively "
                             "looking for log directories, if we encounter a "
                             "subdirectory called 'logs' only descend into "
                             "that directory and ignore the others")
    parser.add_argument('--remove-failed',
                        help="Remove analysis directories for failed runs.\n"
                             "    Specify comma-separated list of failed "
                             "statuses or 'ALL'")
    parser.add_argument('-v', '--version', dest='print_version', action='store_true',
                        help='Print Civet version and exit')
    parser.add_argument('dirs', help="Log directory", nargs=argparse.REMAINDER)
    parser.set_defaults(quiet=False)
    parser.set_defaults(verbose=False)
    parser.set_defaults(fast=False)

    # change default behavior to recursive, keep option to preserve backwards
    # compatibility
    parser.set_defaults(recursive=True)
    args = parser.parse_args()

    remove_statuses = []
    if args.remove_failed is not None:
        remove_statuses = [x.upper() for x in args.remove_failed.split(',')]

    if not args.json:
        verbose = args.verbose
        quiet = args.quiet
    else:
        verbose = False
        quiet = False

    json_output = {}

    job_manager = status.PipelineStatus.get_job_manager()

    if args.print_version:
        version.print_version_string_and_exit()
    
    if verbose and quiet:
        print("--quiet (-q) and --verbose options are mutually exclusive\n",
              file=sys.stderr)
        return 1
    
    dir_list_arg = []

    if args.dirs:
        dir_list_arg = args.dirs
    else:
        dir_list_arg.append('.')

    if args.recursive:
        all_log_dirs = []
        followed_dirs = set()
        for d in dir_list_arg:
            log_dirs = []
            for root, dirs, files in os.walk(d, topdown=True, followlinks=True):

                # in fast mode we short circuit the directory walk if we find
                # a directory called 'logs' and we only descend into that dir
                if args.fast and 'logs' in dirs:
                    dirs[:] = ['logs']

                followed_dirs.add(os.path.realpath(root))
                if job_runner.common.BATCH_ID_LOG in files:
                    log_dirs.append(root)

                # make sure we don't follow any symlinks that point to a dir
                # we've already processed
                for dir in dirs:
                    if os.path.realpath(os.path.join(root, dir)) in followed_dirs:
                        dirs.remove(dir)

            log_dirs.sort()
            all_log_dirs += log_dirs

        if len(all_log_dirs) == 0:
            print("ERROR: no valid log directory found!\n", file=sys.stderr)
            return 1
    else:
        all_log_dirs = dir_list_arg

    for log_dir in all_log_dirs:
    
        log_dir = os.path.abspath(log_dir)
        run_canceled = False
    
        if verbose:
            print("\n\nGetting status for pipeline with log directory at:")
            print("\t{0}".format(log_dir))

        try:
            dir_status = status.PipelineStatus(log_dir, job_manager)
        except ValueError as e:
            print(e, file=sys.stderr)
            continue

        if args.json:
            json_output[log_dir] = dir_status.to_json_serializable()
            continue

        if dir_status.status == "SUBMIT_ERROR":
            print("{0}: Pipeline submission error".format(log_dir), file=sys.stderr)
            continue
    
        # check to see if the log directory was created with civet_run --no-submit
        if dir_status.status == "NO_SUB":
            print(log_dir + ":\n\tThis pipeline was run with --no-submit, so no status is applicable.")
            continue

        if dir_status.aborted and verbose:
            print("WARNING: Pipeline aborted due to non-zero exit value of at least one job.  Details below.\n")

        if dir_status.status == "CANCELED":
            run_canceled = True
            if verbose and dir_status.cancel_message:
                print(dir_status.cancel_message)

        for job in dir_status.jobs:
            if verbose:
                print("\n{0} ({1}):".format(job.name, job.id))

                if job.state == "CANCELED":
                    print("\tJob canceled (state at cancel = {0})".format(
                        status.format_state(job.state_at_cancel)))

                elif "FAILED" in job.state:
                    if job.exit_status == -11:
                        print("\tJob failed (Walltime)")
                    elif job.exit_status < 0:
                        print("\tJob failed (batch error)")
                    else:
                        print("\tFinished=Failure")
                    print("\tExit Status={0}".format(job.exit_status))

                elif job.state == "SUCCESS":
                    print("\tFinished=Success")

                elif job.state == "DELETED":
                    if dir_status.aborted:
                        print("\tpbs_server returned no information for job {0} (job aborted)".format(job.name))
                    elif run_canceled:
                        print("\tpbs_server returned no information for job {0} (pipeline canceled by user)".format(job.name))
                    else:
                        print("\tWARNING=pbs_server returned no information for job {0}.  Job may have been deleted or it may have crashed.".format(job.name))

                elif job.state == "MANAGED":
                    print("\tcivet_status can only get information on complete jobs when pipeline is run in managed batch mode")

                else:
                    print("\t" + status.format_state(job.state))

                if job.walltime is not None:
                    print("\tWalltime={0}".format(job.walltime))

                if job.walltime_requested is not None:
                    print("\tWalltime(Requested)={0}".format(job.walltime_requested))

                if job.state == 'H':
                    print("\tDepends on {}".format(job.dependencies))

        if args.json:
            # no need to print the pipeline summary when we are preparing
            # JSON ouptut.  Just continue on to the next log directory
            continue

        if verbose:
            print("\nSummary:")
        elif not quiet or dir_status.status in FAILURE_STATUSES:
            print("{0}: {1}".format(log_dir, dir_status.status))
            
        if verbose or (not quiet and dir_status.complete_jobs_success != dir_status.total_jobs):
            print("\tTotal Pipeline Jobs: {0}".format(dir_status.total_jobs))
            print("\t\tCompleted Jobs (success): {0}".format(dir_status.complete_jobs_success))
            print("\t\tCompleted Jobs (with error): {0}".format(dir_status.complete_jobs_failure))
            if dir_status.execution_mode == ToolExecModes.BATCH_MANAGED:
                print("\t\tIncomplete jobs: {}".format(dir_status.managed_unknown))
            else:
                print("\t\tRunning Jobs: {0}".format(dir_status.running_jobs))
                print("\t\tPending Jobs (waiting for compute resources): {0}".format(dir_status.queued_jobs))
                print("\t\tPending Jobs (waiting on dependency): {0}".format(dir_status.held_jobs))
            if dir_status.delayed_jobs:
                print("\t\tPending Jobs (delayed start): {0}".format(dir_status.delayed_jobs))
            if dir_status.canceled_jobs:
                print("\t\tCanceled Jobs: {0}".format(dir_status.canceled_jobs))
            if dir_status.deleted_jobs:
                # now that a status.txt file should get created for any job that
                # runs, if we have any "unknown" jobs then it means they were
                # probably deleted (qdel), other possibility is there was a
                # node crash that took out the job
                print("\t\tDeleted Jobs: {0}".format(dir_status.deleted_jobs))

            if dir_status.complete_jobs_failure:
                print_header = True
                for job in dir_status.jobs:
                    # don't show jobs that aren't in a terminated state
                    if job.state in ['QUEUED', 'RUNNING', 'WAITING', 'HELD',
                                     'MANAGED']:
                        continue

                    # skip jobs that exited normally (0) or were canceled
                    # through the batch system:
                    if job.exit_status == 0 or job.exit_status == job_manager.CANCELED_EXIT_STATUS:
                        continue

                    # skip jobs with that are no longer in the queue and have
                    # no exit status, these were canceled while they were still
                    # queued as part of the abort process
                    if dir_status.aborted and job.exit_status is None:
                        continue

                    if print_header:
                        print("\tFailed Jobs:")
                        print_header = False
                    print("\t\t{} ({}): exit_status={}".format(job.name, job.id, job.exit_status))

        if remove_statuses:
            check_remove_run(dir_status, remove_statuses)

        if verbose:
            print("\n\n")

    if args.json:
        print(json.dumps(json_output, indent=2, sort_keys=True))


if __name__ == '__main__':
    main()
